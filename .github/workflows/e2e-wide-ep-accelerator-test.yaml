name: E2E Wide EP Test

on:
  workflow_dispatch:
    inputs:
      pr_or_branch:
        description: 'Pull-request number or branch name to test'
        required: true
        default: 'main'
        type: string
      gateway_type:
        description: 'Gateway type to use'
        required: false
        default: 'istio' # currently only istio supported because thats the default used in infra values
        type: choice
        options:
          - istio
      wait_for_termination:
        description: 'Wait time (in minutes) before terminating for debugging'
        required: true
        default: 0
        type: number

permissions:
  packages: read

env:
  WIDE_EP_PATH: "guides/wide-ep-lws"

jobs:
  setup:
    if: >
      github.event_name == 'workflow_dispatch'
    runs-on: ubuntu-latest
    outputs:
      instance_id: ${{ steps.launch.outputs.instance_id }}
      instance_ip: ${{ steps.launch.outputs.instance_ip }}
    env:
      # g6.12xlarge-4xL4-24GB-GPU
      INSTANCE_TYPE: g6.12xlarge
      AMI_ID: ami-020cba7c55df1f615
      KEY_NAME: ${{ secrets.SSH_KEY_NAME_BOTH }}
      REGION: ${{ secrets.AWS_REGION }}
      HF_TOKEN: ${{secrets.HF_TOKEN}}
      TERMINATION_TIMEOUT: ${{ github.event.inputs.wait_for_termination }}
      DISK_SIZE: "300"
      PR_OR_BRANCH: ${{ github.event.inputs.pr_or_branch || github.event.issue.number }}
      NAMESPACE: ${{ github.event.inputs.namespace }}
      GATEWAY_TYPE: ${{ github.event.inputs.gateway_type || 'istio' }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          persist-credentials: false

      - name: Determine if pr_or_branch is a PR number
        id: check_pr
        run: |
          if [[ "$PR_OR_BRANCH" =~ ^[0-9]+$ ]]; then
            echo "is_pr=true" >> "$GITHUB_OUTPUT"
          else
            echo "is_pr=false" >> "$GITHUB_OUTPUT"
          fi

      - name: Fetch and checkout PR
        if: steps.check_pr.outputs.is_pr == 'true'
        run: |
          git fetch origin pull/"$PR_OR_BRANCH"/head:pr-"$PR_OR_BRANCH"
          git checkout pr-"$PR_OR_BRANCH"

      - name: Checkout branch
        if: steps.check_pr.outputs.is_pr == 'false'
        run: git checkout "$PR_OR_BRANCH"

      - name: Install AWS CLI
        run: |
          sudo apt-get update
          curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
          unzip awscliv2.zip
          sudo ./aws/install --update

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@7474bc4690e29a8392af63c5b98e7449536d5c3a
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID_ET }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY_ET }}
          aws-region: ${{ secrets.AWS_REGION }}

      - name: Launch EC2 instance
        id: launch
        run: |
          INSTANCE_ID=$(aws ec2 run-instances \
            --image-id $AMI_ID \
            --count 1 \
            --instance-type $INSTANCE_TYPE \
            --key-name $KEY_NAME \
            --block-device-mappings "[{
                \"DeviceName\": \"/dev/sda1\",
                \"Ebs\": {
                  \"VolumeSize\": ${DISK_SIZE},
                  \"VolumeType\": \"gp3\",
                  \"DeleteOnTermination\": true
                }
              }]" \
            --tag-specifications "ResourceType=instance,Tags=[{Key=Name,Value=llmd-wide-ep-ci-runner}]" \
            --query 'Instances[0].InstanceId' \
            --output text)

          echo "instance_id=$INSTANCE_ID" >> "$GITHUB_OUTPUT"
          echo "INSTANCE_ID=$INSTANCE_ID" >> $GITHUB_ENV

          echo "Waiting for instance to be running..."
          aws ec2 wait instance-running --instance-ids $INSTANCE_ID

          PUBLIC_IP=$(aws ec2 describe-instances \
            --instance-ids $INSTANCE_ID \
            --query "Reservations[0].Instances[0].PublicIpAddress" \
            --output text)

          echo "instance_ip=$PUBLIC_IP" >> "$GITHUB_OUTPUT"
          echo "INSTANCE_IP=$PUBLIC_IP" >> $GITHUB_ENV

          SECURITY_GROUP_ID=$(aws ec2 describe-instances \
            --instance-ids $INSTANCE_ID \
            --query "Reservations[0].Instances[0].SecurityGroups[0].GroupId" \
            --output text)
          echo "Authorizing SSH in security group $SECURITY_GROUP_ID..."
          aws ec2 authorize-security-group-ingress \
            --group-id $SECURITY_GROUP_ID \
            --protocol tcp \
            --port 22 \
            --cidr 0.0.0.0/0 || echo "SSH rule may already exist ‚Äî continuing"

      - name: Wait for SSH to be ready
        run: |
          echo "${{ secrets.SSH_PRIVATE_KEY_BOTH }}" > key.pem
          chmod 600 key.pem

          echo "Waiting for SSH on $INSTANCE_IP..."
          for i in {1..30}; do
            ssh -o StrictHostKeyChecking=no -i key.pem ubuntu@$INSTANCE_IP "echo connected" && break
            sleep 10
          done

      - name: Setup installer pre-requisites (clone + checkout)
        id: setup-pre-requisite
        run: |
          # pass PR_OR_BRANCH into the remote shell's env, keep heredoc single‚Äëquoted
          ssh -o StrictHostKeyChecking=no -i key.pem \
              ubuntu@$INSTANCE_IP \
              "PR_OR_BRANCH=$PR_OR_BRANCH bash -s" <<'EOF'
            set -euo pipefail
            set -x

            sudo apt-get update -y
            sudo apt-get install -y git

            # Install yq for YAML processing
            echo "Installing yq..."
            sudo wget https://github.com/mikefarah/yq/releases/latest/download/yq_linux_amd64 -O /usr/local/bin/yq && \
            sudo chmod +x /usr/local/bin/yq
            yq --version

            REPO_URL="https://github.com/llm-d/llm-d.git"
            REPO_DIR=$(basename "$REPO_URL" .git)

            echo "üõ†Ô∏è  Cloning: $REPO_URL"
            git clone --depth 1 "$REPO_URL"
            cd "$REPO_DIR"

            if [[ "$PR_OR_BRANCH" =~ ^[0-9]+$ ]]; then
              echo "üõ†Ô∏è  Checking out PR #$PR_OR_BRANCH"
              git fetch origin "pull/$PR_OR_BRANCH/head:pr-$PR_OR_BRANCH"
              git checkout "pr-$PR_OR_BRANCH"
            else
              echo "üõ†Ô∏è  Checking out branch $PR_OR_BRANCH"
              git checkout "$PR_OR_BRANCH"
            fi
          EOF

      - name: Apply Wide EP slim transformation
        id: wide-ep-transformation
        run: |
          ssh -o StrictHostKeyChecking=no -i key.pem ubuntu@$INSTANCE_IP <<'EOF'
            set -euo pipefail
            set -x
            cd llm-d

            echo "Applying wide-ep slim values transform..."
            .github/scripts/e2e/wide-ep-transform.sh ${{ env.WIDE_EP_PATH }}/ms-wide-ep/values.yaml

            # Verify the slimmed down values
            echo "üìã Verifying transformation results..."
            echo "Model in ms-wide-ep:"
            yq e '.modelArtifacts.uri' ${{ env.WIDE_EP_PATH }}/ms-wide-ep/values.yaml
            echo "GPU count in ms-wide-ep decode:"
            yq e '.decode.containers[0].resources.limits["nvidia.com/gpu"]' ${{ env.WIDE_EP_PATH }}/ms-wide-ep/values.yaml
            echo "Replicas in ms-wide-ep prefill:"
            yq e '.prefill.replicas' ${{ env.WIDE_EP_PATH }}/ms-wide-ep/values.yaml

            # Validate YAML syntax
            echo "Validating YAML syntax..."
            yq eval '.' ${{ env.WIDE_EP_PATH }}/ms-wide-ep/values.yaml > /dev/null && echo "ms-wide-ep/values.yaml: Valid"
            echo "‚úÖ All YAML files are valid"

            # Check for malformed resource quantities
            echo "üîç Checking resource quantities format..."
            echo "Decode GPU limits:"
            yq e '.decode.containers[0].resources.limits | keys' ${{ env.WIDE_EP_PATH }}/ms-wide-ep/values.yaml
            echo "Decode GPU requests:"
            yq e '.decode.containers[0].resources.requests | keys' ${{ env.WIDE_EP_PATH }}/ms-wide-ep/values.yaml
            echo "Prefill GPU limits:"
            yq e '.prefill.containers[0].resources.limits | keys' ${{ env.WIDE_EP_PATH }}/ms-wide-ep/values.yaml
            echo "Prefill GPU requests:"
            yq e '.prefill.containers[0].resources.requests | keys' ${{ env.WIDE_EP_PATH }}/ms-wide-ep/values.yaml

            # Display complete transformed files for debugging
            echo ""
            echo "üîç === Completed transformed values files ==="
            echo ""
            echo "ms-wide-ep/values.yaml (transformed):"
            echo "---"
            cat ${{ env.WIDE_EP_PATH }}/ms-wide-ep/values.yaml
            echo "---"
            echo ""
            echo "=== End of values files output ==="
          EOF

      - name: Install prerequisites
        id: prerequisites
        run: |
          ssh -o StrictHostKeyChecking=no -i key.pem ubuntu@$INSTANCE_IP <<'EOF'
            set -euo pipefail
            set -x
            ./llm-d/guides/prereq/client-setup/install-deps.sh | tee ~/install-deps.log
          EOF

      - name: Setup container runtime
        id: setup-docker
        run: |
          ssh -o StrictHostKeyChecking=no -i key.pem ubuntu@$INSTANCE_IP << EOF
            set -e
            sudo apt-get -y install ca-certificates curl
            sudo install -m 0755 -d /etc/apt/keyrings
            sudo curl -fsSL https://download.docker.com/linux/ubuntu/gpg -o /etc/apt/keyrings/docker.asc
            sudo chmod a+r /etc/apt/keyrings/docker.asc
            echo \
              "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/ubuntu \
              $(. /etc/os-release && echo "${UBUNTU_CODENAME:-$VERSION_CODENAME}") stable" | \
              sudo tee /etc/apt/sources.list.d/docker.list > /dev/null

              sudo apt-get update
              sudo apt-get -y install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin
              sudo usermod -aG docker ubuntu
              mkdir -p ~/.config/containers/
          EOF

      - name: Copy docker auth configuration file
        id: docker-auth
        run: |
          echo "${{ secrets.CR_AUTH_JSON }}" > auth.json
          chmod +x auth.json
          rsync -avz -e "ssh -o StrictHostKeyChecking=no -i key.pem" auth.json ubuntu@$INSTANCE_IP:~/
          ssh -o StrictHostKeyChecking=no -i key.pem ubuntu@$INSTANCE_IP << EOF
          mv ~/auth.json ~/.config/containers/
          EOF

      - name: Setup nvidia cuda toolkit
        id: setup-cuda-toolkit
        run: |
          ssh -o StrictHostKeyChecking=no -i key.pem ubuntu@$INSTANCE_IP << EOF
            set -e
            wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2404/x86_64/cuda-keyring_1.1-1_all.deb
            sudo dpkg -i cuda-keyring_1.1-1_all.deb
            sudo apt-get update
            sudo apt-get -y install cuda-toolkit-12-8
            sudo apt-get install -y nvidia-open nvtop nload
          EOF

      - name: Reboot the aws instance
        id: reboot-instance
        run: |
          echo "Rebooting instance..."
          aws ec2 reboot-instances --instance-ids $INSTANCE_ID
          sleep 60
          echo "Waiting for instance to become healthy again..."
          aws ec2 wait instance-status-ok --instance-ids $INSTANCE_ID

      - name: Wait for SSH to be ready after reboot
        run: |
          echo "${{ secrets.SSH_PRIVATE_KEY_BOTH }}" > key.pem
          chmod 600 key.pem

          echo "Waiting for SSH on $INSTANCE_IP..."
          for i in {1..30}; do
            ssh -o StrictHostKeyChecking=no -i key.pem ubuntu@$INSTANCE_IP "echo connected" && break
            sleep 10
          done

      - name: Setup nvidia container toolkit
        id: setup-container-toolkit
        run: |
          ssh -o StrictHostKeyChecking=no -i key.pem ubuntu@$INSTANCE_IP << EOF
            set -e
            curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg \
              && curl -s -L https://nvidia.github.io/libnvidia-container/stable/deb/nvidia-container-toolkit.list | \
                sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | \
                sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list

            sudo apt-get update
            sudo apt-get install -y nvidia-container-toolkit

            sudo sysctl net.core.bpf_jit_harden
            echo "net.core.bpf_jit_harden=0" | sudo tee -a /etc/sysctl.conf
            sudo sysctl -p
            sudo nvidia-ctk runtime configure --runtime=docker && sudo systemctl restart docker
          EOF

      - name: Install minikube
        id: install-minikube
        run: |
          ssh -o StrictHostKeyChecking=no -i key.pem ubuntu@$INSTANCE_IP << EOF
            set -e
            curl -LO https://github.com/kubernetes/minikube/releases/latest/download/minikube-linux-amd64
            sudo install minikube-linux-amd64 /usr/local/bin/minikube && rm minikube-linux-amd64
          EOF

      - name: Start Shared Minikube Cluster
        run: |
          ssh -o StrictHostKeyChecking=no -i key.pem ubuntu@${{ env.INSTANCE_IP }} <<'EOF'
            set -euo pipefail
            set -x
            echo "Starting minikube with gpu support enabled..."
            minikube start --driver docker --container-runtime docker --gpus all --memory no-limit
            sleep 10
            echo "‚úÖ Minikube started."
          EOF

  deploy-and-validate:
    needs: setup
    runs-on: ubuntu-latest
    env:
      INSTANCE_IP: ${{ needs.setup.outputs.instance_ip }}
      HF_TOKEN: ${{ secrets.HF_TOKEN }}
      NAMESPACE: llm-d-wide-ep
      GATEWAY_TYPE: ${{ github.event.inputs.gateway_type || 'istio' }}

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          persist-credentials: false

      - name: Setup SSH Key
        run: |
          echo "${{ secrets.SSH_PRIVATE_KEY_BOTH }}" > key.pem
          chmod 600 key.pem

      - name: Install chart dependencies (CRDs and Gateway provider)
        env:
          GATEWAY_TYPE: ${{ env.GATEWAY_TYPE }}
        run: |
          ssh -o StrictHostKeyChecking=no -i key.pem ubuntu@$INSTANCE_IP "GATEWAY_TYPE=$GATEWAY_TYPE bash -s" <<'EOF'
            set -euo pipefail
            set -x
            cd llm-d/guides/gateway-provider
            ./install-gateway-provider-dependencies.sh
            helmfile apply -f ${GATEWAY_TYPE}.helmfile.yaml
          EOF

      - name: Install LeaderWorkerSet helm chart and wait for controller
        run: |
          ssh -o StrictHostKeyChecking=no -i key.pem ubuntu@$INSTANCE_IP << EOF
            set -euo pipefail
            set -x
            export LWS_CHART_VERSION=0.7.0
            helm install lws oci://registry.k8s.io/lws/charts/lws \
              --version=${LWS_CHART_VERSION} \
              --namespace lws-system \
              --create-namespace \
              --wait --timeout 300s

            kubectl wait deploy/lws-controller-manager -n lws-system --for=condition=available --timeout=5m
          EOF

      - name: Deploy Wide EP example
        run: |
          ssh -o StrictHostKeyChecking=no -i key.pem ubuntu@$INSTANCE_IP "GATEWAY_TYPE=$GATEWAY_TYPE bash -s" << EOF
            set -euo pipefail
            set -x
            cd llm-d/${{ env.WIDE_EP_PATH }}
            echo "Deploying Wide EP example with slim configuration..."
            helmfile apply -e ${GATEWAY_TYPE} \
              --set gateway.service.type=NodePort \
              --skip-schema-validation | tee ~/wide-ep-deployment.log
            echo "---------------------------------------" >> ~/wide-ep-deployment.log
          EOF

      - name: Add HuggingFace secret to cluster
        run: |
          ssh -o StrictHostKeyChecking=no -i key.pem ubuntu@$INSTANCE_IP "HF_TOKEN=$HF_TOKEN NAMESPACE=$NAMESPACE bash -s" <<'EOF'
            set -euo pipefail
            set -x
            export HF_TOKEN_NAME=${HF_TOKEN_NAME:-llm-d-hf-token}
            echo "Adding HuggingFace token as a secret named $HF_TOKEN_NAME in namespace $NAMESPACE..."
            kubectl create secret generic ${HF_TOKEN_NAME} \
              --from-literal="HF_TOKEN=${HF_TOKEN}" \
               --namespace "${NAMESPACE}" \
               --dry-run=client -o yaml | kubectl apply -f -
          EOF

      - name: Upload helm get all
        run: |
          ssh -o StrictHostKeyChecking=no -i key.pem ubuntu@$INSTANCE_IP "NAMESPACE=$NAMESPACE bash -s" << EOF
            set -euo pipefail
            set -x
            /bin/sh llm-d/.github/scripts/e2e/helm-get-all.sh \
              ~/wide-ep-deployment.log \
              ms-wide-ep "$NAMESPACE"
          EOF

      - name: Wait for all pods to be ready
        run: |
          echo "‚è≥ Waiting for all pods in namespace to become ready..."
          ssh -o ServerAliveInterval=60 -o StrictHostKeyChecking=no -i key.pem ubuntu@$INSTANCE_IP "NAMESPACE=$NAMESPACE bash -s" <<'EOF'
            set -euo pipefail
            kubectl wait pod \
              --for=condition=Ready \
              --all \
              -n "${NAMESPACE}" \
              --timeout=30m
            echo "‚úÖ All pods are ready."

            kubectl get pods -n "${NAMESPACE}"

          EOF

      - name: Show deployment status
        run: |
          ssh -o StrictHostKeyChecking=no -i key.pem ubuntu@$INSTANCE_IP <<EOF
            set -euo pipefail
            echo "=== LWS ==="
            kubectl get leaderworkersets -n "${NAMESPACE}"
            echo ""
            echo "=== Stateful Sets ==="
            kubectl get statefulset -n "${NAMESPACE}"
            echo ""
            echo "=== Deployments ==="
            kubectl get deployments -n "${NAMESPACE}"
            echo ""
            echo "=== Replica Sets ==="
            kubectl get replicasets -n "${NAMESPACE}"
            echo ""
            echo "=== Pods ==="
            kubectl get pods -n "${NAMESPACE}"
            echo ""
            echo "=== Services ==="
            kubectl get svc -n "${NAMESPACE}"
            echo ""
            echo "=== Helm releases ==="
            helm list -n "${NAMESPACE}" || true
            echo ""
            echo "=== Wide-EP-specific resources ==="
            echo "Inference Models:"
            kubectl get inferencemodels -n "${NAMESPACE}" || true
            echo "Inference Pools:"
            kubectl get inferencepools -n "${NAMESPACE}" || true
            echo "HTTP Routes:"
            kubectl get httproutes -n "${NAMESPACE}" || true
          EOF

      - name: Wide EP inference test
        run: |
          ssh -o ServerAliveInterval=60 -o StrictHostKeyChecking=no -i key.pem ubuntu@"$INSTANCE_IP" <<EOF
            set -euo pipefail
            set -x
            cd llm-d/.github/scripts/e2e

            echo "üß™ Running Wide EP specific tests..."
            # Test the specific model and endpoints for Wide EP setup
            ./e2e-validate.sh -n "${NAMESPACE}"

            # Additional Wide EP validation
            echo "üîç Verifying Wide EP specific functionality..."

            # Check that we have both prefill and decode pods
            PREFILL_PODS=\$(kubectl get pods -n "${NAMESPACE}" -l llm-d.ai/role=prefill --no-headers | wc -l)
            DECODE_PODS=\$(kubectl get pods -n "${NAMESPACE}" -l llm-d.ai/role=decode --no-headers | wc -l)

            echo "Prefill pods: \$PREFILL_PODS"
            echo "Decode pods: \$DECODE_PODS"

            if [ "\$PREFILL_PODS" -lt 2 ] || [ "\$DECODE_PODS" -lt 2 ]; then
              echo "‚ùå Missing prefill or decode pods for Wide EP setup"
              exit 1
            fi

            echo "‚úÖ Wide EP validation completed successfully"
          EOF

      - name: Collect and upload Kubernetes pod logs
        if: always()
        run: |
          echo "Collecting logs for namespace: ${NAMESPACE}"
          REMOTE_TARBALL="pod-logs-wide-ep.tar.gz"
          ssh -o StrictHostKeyChecking=no -i key.pem ubuntu@$INSTANCE_IP << EOF
            mkdir -p pod-logs-wide-ep
            cd pod-logs-wide-ep
            echo "Fetching ${NAMESPACE} pods log..."
            kubectl get pods -n "${NAMESPACE}" --no-headers -o custom-columns=":metadata.name" \
            | xargs -I{} sh -c 'kubectl logs --all-containers=true -n "${NAMESPACE}" {} > "{}.log" 2>&1'
            echo "Fetching ${NAMESPACE} pods descriptions..."
            kubectl get pods -n "${NAMESPACE}" --no-headers -o custom-columns=":metadata.name" \
            | xargs -I{} sh -c 'kubectl describe pod -n "${NAMESPACE}" {} > "{}-describe.log" 2>&1'
            mv ~/wide-ep-deployment.log . || true
            mv ~/install-deps.log . || true
            cd ..
            tar -czf "$REMOTE_TARBALL" pod-logs-wide-ep
          EOF
          scp -o StrictHostKeyChecking=no -i key.pem ubuntu@$INSTANCE_IP:"$REMOTE_TARBALL" .
          mkdir -p extracted-logs-wide-ep
          tar -xzf "$REMOTE_TARBALL" -C extracted-logs-wide-ep
          echo "Logs downloaded from the AWS instance."

      - name: Upload pod logs as artifact
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: llmd-pod-logs-wide-ep
          path: extracted-logs-wide-ep

  terminate:
    needs: [setup, deploy-and-validate]
    if: always()
    runs-on: ubuntu-latest
    env:
      INSTANCE_ID: ${{ needs.setup.outputs.instance_id }}
      REGION: ${{ secrets.AWS_REGION }}
      TERMINATION_TIMEOUT: ${{ github.event.inputs.wait_for_termination }}

    steps:
      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@7474bc4690e29a8392af63c5b98e7449536d5c3a
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID_ET }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY_ET }}
          aws-region: ${{ secrets.AWS_REGION }}

      - name: Pause before termination (debug window)
        if: env.TERMINATION_TIMEOUT != '0'
        run: |
          echo "‚è≥  Debug pause enabled for $TERMINATION_TIMEOUT minute(s)‚Ä¶"
          for ((i=1; i<=TERMINATION_TIMEOUT; i++)); do
            printf "  ‚è≥  %02d/%02d minute(s) elapsed\n" "$i" "$TERMINATION_TIMEOUT"
            sleep 60
          done

      - name: Terminate EC2 instance
        run: |
          echo "Terminating instance $INSTANCE_ID..."
          aws ec2 terminate-instances --instance-ids $INSTANCE_ID
          echo "Waiting for instance to be terminated..."
          aws ec2 wait instance-terminated --instance-ids $INSTANCE_ID
